---
title: "Project Ke-3"
author: "huans"
date: "2022-10-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Customer Segmentation
Baik sebelum melakukan analysis ada beberapa tahapan yang harus kita pahami yaitu
6 FASE ANALISIS DATA

1. Bertanya/ ask
kita melakukan dua hal yaitu mendefinisikan masalah yang harus dipecahkan dan kita memastikan bahwa kita memahami sepenuhnya harapan dari pemangku kepentingan/ stakeholder. Ini membantu anda tetap fokus pada masalah itu sendiri bukan hanya gejalanya. Pertanyaan 5 whys membantu pada tahap ini. Berkomunikasi dengan pemangku kepentingan anda adalah kunci untuk membuat anda tetap terlibat dan di jalur yang tepat selama pelaksanaan proyek. Mendefinisikan masalah berarti anda melihat keadaan saat ini dan mengidentifikasi keadaan dibandingkan dengan keadaan ideal. Berikut ini adalah beberapa pertanyaan yang sering diajukan
Apa masalah yang kita coba selesaikan?, Apa tujuan dari analisis ini?, Apa pelajaran yang kita harapkan dari masalah itu?

2. Mempersiapkan/ prepare
Ini adalah langkah dimana data analyst mengumpulkan dan menyimpan data yang akan kita gunakan untuk proses analisis berikutnya. Mengidentifikasi jenis data apa yang paling berguna untuk memecahkan suatu masalah tertentu. data dan hasil analisis Anda yang objektif dan tidak bias adalah sangat penting. Dengan kata lain, setiap keputusan yang dibuat dari analisis Anda harus selalu didasarkan pada fakta dan kejujuran, serta tidak memihak

3. Memproses/ process
Hal yang dilakukan pada tahap ini adalah menemukan dan menghilangkan setiap kesalahan dan ketidakakuratan yang dapat menghambat perolehan hasil. Biasanya yang dilakukan adalah membersihkan data, mengubahnya menjadi format yang lebih berguna, menggabungkan dua atau lebih, untuk memperoleh informasi lebih lengkap dan menghilangkan data pencilan (outlier) yaitu data observasi yang dapat memberatkan ketimpangan informasi.
Memeriksa data yang kita persiapkan untuk memastikan data yang lengkap dan benar. Tahap ini adalah tahap di mana kita harus memperoleh detail data dengan benar. Jadi Kita juga akan memperbaiki kesalahan ketik, inkonsistensi, atau data yang hilang dan tidak akurat. Untuk melengkapinya, kita juga menerapkan strategi untuk memverifikasi dan membagikan pembersihan data kita dengan pemangku kepentingan

4. Menganalisis/ analyze
Menganalisis data untuk menemukan pola, hubungan, dan tren. Diperlukan penggunaan alat untuk mengubah dan mengatur informasi sehingga Anda dapat menarik kesimpulan yang bermanfaat, membuat prediksi, serta memberi saran yang tepat untuk pengambilan keputusan. Misal menggunakan spreadshet, R, Python, SQL

5. Membagikan/share
Visualisasi
Para analis membagikan temuan dan rekomendasi mereka kepada pihak yang memang berkepentingan. Bagaimana analis data menafsirkan hasil dan membagikannya dengan orang lain untuk membantu pemangku kepentingan membuat keputusan berdasarkan data secara efektif. Pada tahap berbagi, visualisasi adalah teman terbaik seorang analis data. visualisasi itu penting untuk membuat orang lain memahami apa yang data Anda katakan. Dengan visual yang tepat, fakta dan angka menjadi jauh lebih mudah untuk dilihat dan konsep yang kompleks menjadi lebih mudah dipahami.

6. Bertindak/ act
Hal ini berkaitan erat dengan menerapkan wawasan kita untuk menyelesaikan masalah, mengambil keputusan, membuat hal baru. Saat yang menyenangkan ketika suatu perusahaan menerima semua wawasan yang telah kita sediakan, sebagai data analyst, dan mengelola data tersebut sedemikian rupa untuk memecahkan asal masalah perusahaan tersebut

<br>

#### STUDY CASE
Untuk project kali ini saya hanya akan menggunakan dataset yang jumlahnya sedikit tapi cukup mewakili. Hasil dari project ini adalah menerapkan algoritma tertentu untuk menghasilkan clustering terhadap customer berdasarkan dataset yang tersedia .Dalam project ini saya menggunakan algoritma K-Means Clustering, kemudian melakukan ETL pada dataset, membuat visualisasi, dan membuat objek clustering  agar model dapat digunakan untuk mengcluster data baru

<br>
<br> 

#### Bertanya/ ask
Dalam study case sudah dijelaskan bahwa tujuan dari project ini adalah melakukan clustering terhadap dataset yang tersedia dan membaut objek clustering agar model dapat digunakan untuk mengcluster data baru.

<br>
<br> 

#### Mempersiapkan/ prepare
disini saya menggunakan dataset bernama customer_segments.txt yang mana datanya dipisahkan oleh tab

<br> 
<br> 

#### Memproses/ process

Seperti yang sudah disinggung di study case.  saya menggunakan R dan algoritma K-Mean Clustering. Sebelum melakukan tahap process saya akan jelaskan sedikit apa itu clustering dan algoritma K-Means
<br>
<br>
**clustering**
<br>
Clustering adalah proses pembagian objek-objek ke dalam beberapa kelompok (cluster) berdasarkan tingkat kemiripan antara satu objek dengan yang lain
<br>
<br>
**algoritma K-Mean Clustering**
<br>
 K-means adalah algoritma yang membagi data menjadi sejumlah partisi dengan cara sederhana: mencari kedekatan dari tiap titik pada suatu cluster dengan sejumlah nilai rata-rata atau mean. K-means merupakan tipe clustering dengan centroid based (titik pusat)(centroid artinya rata-rata cluster ). Artinya kesamaan dari objek/sampel dihitung dari seberapa dekat objek itu dengan centroid atau titik pusat.
<br>
<br>
**Kenapa Perlu Bantuan Algoritma untuk Customer Segmentation?**
<br>
Agar kita dapat membagi-bagi segmen customer dengan gampang, Dapat membantu kita menentukan jumlah clustering yang optimal, Dapat memberikan hasil jauh lebih cepat Karena bisa memberikan best practice
<br>
<br>
**Pentingnya Customer Segmentation**
<br>
Setelah kita mengetahui apa itu clustering dan k-means sekarang saya akan menjelaskan Kenapa Customer Segmentation Penting. Customer segmentation itu penting karena dapat membuat pesan pemasaran yang lebih mengena ke tiap pelanggan, Bisa lebih mengenal customer / pelanggan, dan Biaya pemasaran bisa menjadi lebih rendah.
<br>
<br>
Customer segmentation adalah proses penting yang diperlukan di bisnis untuk mengenal customer dengan lebih baik Dengan demikian proses bisnis di marketing (pemasaran) dan CRM (customer relationship management) bisa dilakukan lebih tajam. Contoh: pesan marketing bisa lebih personal untuk setiap segment dengan biaya lebih optimal. Dengan proses yang lebih tajam, performa bisnis berpotensi tinggi menjadi lebih baik juga. Untuk menemukan segmentasi yang baik, perlu proses analisa data dari profile customer yang cukup banyak dan rutin. Ini bisa dibantu dengan algoritma komputer.


<br>
<br>


**Cek data isi data frame**
```{r}
#import dataset
dataset_raw = read.csv('customer_segments.txt', sep="\t")

#cek tipe data
class(dataset_raw)

#tampilkan 6 data teratas
head(dataset_raw)
```

<br> 


```{r include=TRUE}
#Menyajikan informasi tiap kolom dataset dalam format yang compact
str(dataset_raw)
```

Dari data diatas dapat kita ketahui jumlah baris data ada 50 baris yang terdiri dari 7 column yaitu Customer_ID, Nama.Pelanggan, Jenis.Kelamin, Umur, Profesi, Tipe.Residen, NilaiBelanjaSetahun

<br> 

```{r}
#Cek nilai null
is.null(dataset_raw)
```
Dari hasil diatas kita dapat mengetahui bahwa dataset tidak memiliki nilai null

<br>
<br>
**Konversi Data dari chr ke int**
<br>
Seperti yang kita lihat diatas ada beberapa kolom yang tipe datanya masih chr alias berupa tipe kategorik berupa text.Untuk menggunakan algoritma K-Mean Clustering kita harus merubah tipe data kategori yang berupa teks menjad numerik, hal ini karena algoritma tsb hanya bisa memproses data bertipe numerik. Disini kita akan merubah tipe data dari kolom "Jenis.Kelamin", "Profesi", "Tipe.Residen" menjadi numerik menggunakan fungsi data.matrix
<br>

```{r}
#Konversi Data dengan data.matrix
pelanggan_matrix <- data.matrix(dataset_raw[c("Jenis.Kelamin", "Profesi", "Tipe.Residen")])
```
```{r include=TRUE}
#tampilkan 6 data teratas
head(pelanggan_matrix)

```
Jika kita lihat diatas data sudah berhasil di convert ke bentuk numerik

<br>
<br>
**Menggabungkan Hasil Konversi**
```{r}
# Penggabungan data
dataset_raw <- data.frame(dataset_raw, pelanggan_matrix)

# Tampilkan kembali data hasil penggabungan
# tampilkan 6 data teratas
head(dataset_raw)
```
penggabungan ini akan menambahkan kolom bernama "Jenis.Kelamin.1", "Profesi.1", dan "Tipe.Residen.1"

<br>
<br>

**Menormalisasikan Nilai Belanja**

```{r}
#kita cek nilai dari column "NilaiBelanjaSetahun"
cek_NilaiBelanjaSetahun = dataset_raw[c("NilaiBelanjaSetahun")]
head(cek_NilaiBelanjaSetahun)
```
Dapat dilihat diatas nominal dari column  "NilaiBelanjaSetahun" berkisar jutaan yang mana ini harus dilakukan normalisasi hal ini karena nilai pada column lain yaitu column "Jenis.Kelamin.1", "Profesi.1", dan "Tipe.Residen.1" hanya bernilai satuan. Hal ini menunjukkan column "NilaiBelanjaSetahun" ini berada pada skala yang sangat jauh berbeda. Sehingga bisa dikatakan bahwa data tidak seimbang.
<br><br>
Ketika membangun sebuah model, seperti regresi linear, atau pun k-means ini column  "NilaiBelanjaSetahun" akan sangat mempengaruhi prediksi dari model karena nilainya yang jauh lebih besar daripada column lainnya, walaupun bukan berarti column "NilaiBelanjaSetahun" jauh lebih penting dari column lainnya tersebut. Solusinya, kita bisa menerapkan normalization untuk menyeimbangkan data.


```{r}
#Normalisasi Nilai
dataset_raw$NilaiBelanjaSetahun <- dataset_raw$NilaiBelanjaSetahun / 1000000

#kita cek nilai dari column "NilaiBelanjaSetahun"
cek_NilaiBelanjaSetahun = dataset_raw[c("NilaiBelanjaSetahun")]
head(cek_NilaiBelanjaSetahun)
```
Dapat kita lihat nilai hasil normalisasi pada column "NilaiBelanjaSetahun" sudah menjadi jauh lebih kecil dan sudah seimbang dengan data numerik pada column "Jenis.Kelamin.1", "Profesi.1", dan "Tipe.Residen.1"

<br>
<br>

**Membuat Data Master**
<br>
Data ringkas dan unik ini untuk selanjutnya kita sebut sebagai data referensi atau data master.

```{r}
#Membuat Data Master
Profesi <- unique(dataset_raw[c("Profesi","Profesi.1")])
Profesi

```
Terlihat ya datanya sudah diringkas dengan teks kategori beserta pasangan numeriknya. Kemudian perhatikan juga angka-angka 1,2,3,17 dan 31 yang terdapat di bagian paling kiri. Ini menunjukkan posisi baris ditemukannya teks tersebut. untuk column yang lain juga sama 

```{r}
Jenis.Kelamin <- unique(dataset_raw[c("Jenis.Kelamin","Jenis.Kelamin.1")])
Jenis.Kelamin
Tipe.Residen <- unique(dataset_raw[c("Tipe.Residen","Tipe.Residen.1")])
Tipe.Residen
```
<br>
<br>
**Fungsi kmeans**
<br>
Sebelum masuk ke coding. disini saya akan jelaskan lebih dalam tentang K-means clustering
<br>
<br>
**perlu mendefinisikan jumlah centroid (K) yang diinginkan**
<br>
semisalnya kita menetapkan jumlah K = 3; maka pada awal iterasi, algorithm akan secara random menentukan 3 centroid. Setelah itu, objek/sample/data point yang lain akan dikelompokkan sebagai anggota dari salah satu centroid yang terdekat, sehingga terbentuk 3 cluster data. Clustering yang baik adalah cluster yang data point-nya saling rapat/sangat berdekatan satu sama lain dan cukup berjauhan dengan objek/data point di cluster yang lain
<br>
<br>
**Penjelasan beberapa variable dan fungsi yang digunakan**
<br>
**x**: data yang digunakan, dimana semua isi datanya harus berupa numerik.
<br>
**centers**: jumlah cluster yang diinginkan
<br>
**nstart**: parameter data dan jumlah segmen saja tidak cukup. Perlu digunakan parameter ketiga yaitu nstart, yang merupakan jumlah kombinasi acak yang dihasilkan secara internal oleh R. Berdasarkan jumlah yang diberikan, algoritma akan memilih mana yang terbaik dari kombinasi-kombinasi tersebut.
<br>
**function seet.seed** : Ini berguna agar kita "menyeragamkan" daftar nilai acak yang sama dari kmeans sehingga kita mendapatkan output yang sama.

```{r}
#mendefinisikan column yang digunakan dalam algoritma k-means
field_yang_digunakan = c("Jenis.Kelamin.1", "Umur", "Profesi.1", "Tipe.Residen.1","NilaiBelanjaSetahun")
# Bagian K-Means misal kita coba untuk 5 cluster
set.seed(100)
segmentasi <- kmeans(x=dataset_raw[field_yang_digunakan], centers=5, nstart=25)
#cek hasil clustering
segmentasi
```
Mungkin banyak yang bingung maksud dari output dari variable segmentasi diatas. Baik saya akan jelaskan perbagian
<br><br>
**K-means clustering with 5 clusters of sizes 5, 12, 14, 9, 10**
<br>
bagian tersebut menunjukkan Ukuran / jumlah titik data pada tiap cluster, Ini artinya dengan k-means kita telah membagi dataset pelanggan dengan 5 cluster, dimana: Cluster ke-1 memiliki 14 data, Cluster ke-2 memiliki 5 data, Cluster ke-3 memiliki 9 data, Cluster ke-4 memiliki 12 data, Cluster ke-5 memiliki 10 data
<br><br>

**Cluster means:**
<br>
bagian tersebut menunjukkan Nilai rata-rata (centroid) dari tiap cluster. yang berisi angka 1 sampai dengan 5 adalah mewakili nomor cluster.
<br><br>
**kolom ke 1**, Kolom pertama Kolom Kelamin.1 menunjukkan nilai rata-rata dari data jenis kelamin yang telah dikonversi menjadi numerik, dengan angka 1 mewakili Pria dan angka 2 mewakili wanita. jika kita lihat pada cluster 1 nilanya 1.40 itu artinya pada cluster lebih didominasi jenis kelamin laki-laki
<br><br>
**kolom ke 2**, Kolom Umur adalah representasi dari dataset awal tanpa mengalami konversi. Terlihat untuk cluster ke-1 umur rata-rata adalah 61 tahun, umur 31 tahun untuk cluster ke-2, dan seterusnya.
<br><br>
**kolom ke 3**, Kolom Profesi.1 Kolom Profesi.1 menunjukkan nilai rata-rata data Profesi untuk tiap cluster yang telah dikonversi menjadi numerik, yaitu angka 1 s/d 5.
Angka 1, 2, 3, 4, dan 5 di kolom ini masing-masingnya secara berurutan mewakili Ibu Rumah Tangga, Mahasiswa, Pelajar, Professional, dan Wiraswasta. Terlihat untuk seluruh cluster bahwa nilai profesi berada dalam rentang 3.5 s/d 4.2 (3.5< profesi <= 4.2). Hal ini menunjukkan bahwa profesi cenderung ke ke Professional, dan secara tegas cluster keempat memiliki profesi berupa Professional.
<br><br>
**kolom ke 4**, Kolom Tipe.Residen.1 menunjukkan representasi data Tipe.Residen yang telah dikonversi menjadi numerik dengan angka 1 mewakili Cluster dan 2 mewakili Sector. Ini juga didapatkan dari hasil konversi data menjadi numerik pada praktek sebelumnya. Untuk seluruh cluster, terlihat data cukup tersebar antara Sector dan Cluster terutama untuk cluster ke-4 dimana nilai kolom ini di angka 1.555.
<br><br>
**kolom ke 5**, kolom NilaiBelanjaSetahun cukup signifikan pembagiannya untuk tiap cluster. Cluster ke-1 dan ke-4 memiliki nilai belanja lebih tinggi dibandingkan ketiga cluster lainnya.
<br><br>
**Clustering vector:**
<br>
Pembagian cluster dari tiap elemen data berdasarkan posisinya, Vector ini dimulai dari angka 1, yang artinya data pertama dari dataset kita akan dialokasikan pada nomor cluster 1 dst
<br><br>
**Within cluster sum of squares by cluster:**
<br>
Jumlah jarak kuadrat dari tiap titik ke centroidnya. Ini adalah metrik yang bisa kita gunakan untuk menjawab seberapa baik jumlah cluster yang kita bentuk? Apakah dibagi 2, 5, 10 atau 30?. Clustering yang ideal adalah yang jumlah SSE paling kecil dan jumlah Cluster yang kecil
<br><br>
**sum of squares (SS) /  Sum of Squared Errors (SSE)** adalah jumlah "jarak kuadrat" perbedaan tiap titik data dengan mean atau centroidnya. Semakin besar nilai SS menyatakan semakin lebarnya perbedaan antar tiap titik data di dalam cluster tersebut.Nilai 58.21123 adalah SS untuk cluster ke-1, 174.85164 adalah SS untuk cluste ke-2, dan seterusnya. Semakin kecil nilainya berpotensi semakin baik.
<br>
rumus SSE = Σ(yi-centroid tiap cluster)²
<br>
**total_SS** adalah SS untuk seluruh titik terhadap nilai rata-rata global, bukan untuk per cluster. Nilai ini selalu tetap dan tidak terpengaruh dengan jumlah cluster. Semakin kecil nilainya berpotensi semakin baik.
<br>
**between_SS** adalah total_SS dikurangi dengan jumlah nilai SS seluruh cluster.
<br>
**(between_SS / total_SS)** adalah rasio antara between_SS dibagi dengan total_SS. Semakin besar persentasenya, umumnya semakin baik.
<br>
**Nilai 92.4%** adalah nilai persentase rasio antara between_SS dan total_SS
<br><br>
**Clustering vector:**
<br>
Merupakan informasi tentang Komponen informasi lain yang terkandung di dalam objek kmeans ini(segmentasi$withinssr)
<br><br>
**DIATAS TADI ADALAH NILAI JIKA KITA MENGGUNAKAN  NILAI CENTERS = 5, SEKARANG KITA COBA BANDINGKAN JIKA NILAI CENTERS = 2**
```{r}
#mendefinisikan column yang digunakan dalam algoritma k-means
field_yang_digunakan = c("Jenis.Kelamin.1", "Umur", "Profesi.1", "Tipe.Residen.1","NilaiBelanjaSetahun")
# Bagian K-Means misal kita coba untuk 5 cluster
set.seed(100)
segmentasi2 <- kmeans(x=dataset_raw[field_yang_digunakan], centers=2, nstart=25)
#cek hasil clustering
segmentasi2
```
bisa dilihat niali SSE per cluster sekarang jauh lebih tinggi  dan rasio antara between_SS dan total_SS semakin mengecil hal ini umum terjadi karena jika jumlah cluster semakin banyak maka nilai SSE nya juga semakin kecil . Tapi clustering yang optimal adalah yang memiliki Jumlah cluster paling sedikit dengan nilai SSE yang besar hal tersebut dapat kita ketahui dengan menerapkan elbow effect yang mana akan kita bahas setelah ini
<br><br>

**Simulasi Jumlah Cluster dan SS**
```{r}
# Bagian K-Means
set.seed(100)
sse <- sapply(1:10, function(param_k) {kmeans(dataset_raw[field_yang_digunakan], param_k, nstart=25)$tot.withinss})
sse
```
**Penjelasan**
<br>
tot.withinss = total nilai dari withinss merupakan Total penjumlahan dari tiap SS dari withinss
withinss = 	Total Sum of Squares per cluster, misal pada centers=5 diatas nilai ss nya untuk tiap cluster itu disebut withinss yaitu 58.21123, 174.85164, 316.73367, 171.67372, 108.49735 jika semua nilai itu dijumlahkan akan menjadi nilai dari tot.withinss = 829.9676
<br><br>
maksud kode Simulasi Jumlah Cluster dan SS diatas adalah merupakan nilai tot.withinss untuk setiap nilai centers antara nilai centers 1 sampai 10 yang mana nilai nya kita gunakan untuk membuat grafik agar kita dapat melihak elbow effect nya

**Grafik Elbow Effect**
```{r}
#pertama kita import library ggplot2 untuk membuat grafiknya
library(ggplot2)
#membuat grafik agar kita dapat melihat elbow effectnya
set.seed(100)
sse <- sapply(1:10, function(param_k){kmeans(dataset_raw[field_yang_digunakan], param_k, nstart=25)$tot.withinss})

jumlah_cluster_max <- 10
ssdata = data.frame(cluster=c(1:jumlah_cluster_max),sse)
ggplot(ssdata, aes(x=cluster,y=sse)) +
                geom_line(color="red") + geom_point() +
                ylab("Within Cluster Sum of Squares") + xlab("Jumlah Cluster") +
                geom_text(aes(label=format(round(sse, 2), nsmall = 2)),hjust=-0.2, vjust=-0.5) +
  scale_x_discrete(limits=c(1:jumlah_cluster_max))
```
memilih jumlah cluster yang terletak pada “elbow” dalam SSE plot, yaitu ketika nilai SSE mulai menurun secara perlahan. Jika dilihat pada gambar maka jumlah cluster yang optimal adalah K = 5.

<br><br>

**Menamakan Segmen**
<br>
kita akan menamakan segmen sesuai dengan karakteristiknya

```{r}
#cek hasil segmentasi yang optimal yaitu centers=5
segmentasi$center
```


```{r}
#menamakan segmen
Segmen.Pelanggan <- data.frame(cluster = c(1,2,3,4,5),
                               Nama.Segmen = c("Silver Youth Gals", "Diamond Senior Member", 
                                               "Gold Young Professional", "Diamond Professional", 
                                               "Silver Mid Professional"))
```
kita coba namakan cluster 1 s/d 5 sebagai berikut:
<br>
<br>
Cluster 1 : Diamond Senior Member: alasannya adalah karena umurnya rata-rata adalah 61 tahun dan pembelanjaan di atas 8 juta.
<br>
Cluster 2 : Gold Young Professional: alasannya adalah karena umurnya rata-rata adalah 31 tahun, professional dan pembelanjaan cukup besar.
<br>
Cluster 3 : Silver Youth Gals: alasannya adalah karena umurnya rata-rata adalah 20, wanita semua, profesinya bercampur antar pelajar dan professional serta pembelanjaan sekitar 6 juta.
<br>
Cluster 4 : Diamond Profesional: alasannya adalah karena umurnya rata-rata adalah 42 tahun, pembelanjaan paling tinggi dan semuanya professional.
<br>
Cluster 5 : Silver Mid Professional: alasannya adalah karena umurnya rata-rata adalah 52 tahun dan pembelanjaan sekitar 6 juta.
<br>
<br>

**Menggabungkan Referensi**
semuanya digabungkan di satu variable dengan tipe list, dan ini akan jadi model kita yang dapat disimpan ke dalam file dan digunakan ketika diperlukan

```{r}
#membentuk suatu model
Identitas.Cluster <- list(Profesi=Profesi, 
                          Jenis.Kelamin=Jenis.Kelamin, 
                          Tipe.Residen=Tipe.Residen,
                          Segmentasi=segmentasi, 
                          Segmen.Pelanggan=Segmen.Pelanggan,
                          field_yang_digunakan=field_yang_digunakan) 
#Menyimpan Objek dalam Bentuk File
#File ini kemudian dapat dibuka kembali sebagai objek ke depannya
saveRDS(Identitas.Cluster, "cluster.rds")
```

jadi hasil coding Identitas.Cluster  diatas akan menghasilkan variabel Segmen.Pelanggan yang berisi  data master dari profesi, jenis.kelamin,tipe.residen, segmentasi, segmen.pelanggan, field_yang_digunakan. yang mana memiliki semua aset yang diperlukan untuk mengalokasikan data baru ke segmen yang sesuai alias anda sudah membentuk suatu model. Model ini adalah objek yang bisa digunakan untuk mengolah data baru dan terdiri dari objek kmeans, variable referensi hasil konversi teks ke numerik, dan juga penamaan cluster.
<br>
<br>
objek hasil pengolahan algoritma K-Means dan variable-variable terkait yang kita hasilkan sebelumnya harus dapat digunakan ke kasus riil sehingga satu siklus lengkap terjadi. Kasus riil untuk clustering kita adalah cukup sederhana: bagaimana data baru dapat otomatis membantu tim marketing dan CRM untuk mengidentifikasi segmen mana pelanggan tersebut berada dengan cepat. Dengan kecepatan identifikasi, maka organisasi atau bisnis dapat dengan cepat bergerak dengan pesan marketing yang efektif dan memenangkan persaingan.
<br>
<br>

# Menerapkan hasil model pada kasus rill

**Data Baru**
Disini model clustering k-means kita coba untuk mengclussterkan data baru

```{r}
databaru <- data.frame(Customer_ID="CUST-100", 
                       Nama.Pelanggan="Rudi Wilamar",
                       Umur=20,
                       Jenis.Kelamin="Wanita",
                       Profesi="Pelajar",
                       Tipe.Residen="Cluster",
                       NilaiBelanjaSetahun=3.5)
databaru
```
<br>
<br>
**Memuat Objek Clustering dari File**

```{r}
Identitas.Cluster <- readRDS(file="cluster.rds")
Identitas.Cluster
```

**Merge dengan Data Referensi**
<br>
digunakan untuk menggabungkan data baru ini untuk mendapatkan konversi numerik dari field Jenis.Kelamin, Profesi dan Tipe.Residen
```{r}
# Masukkan perintah untuk penggabungan data
databaru <- merge(databaru, Identitas.Cluster$Profesi)
databaru <- merge(databaru, Identitas.Cluster$Jenis.Kelamin)
databaru <- merge(databaru, Identitas.Cluster$Tipe.Residen)
databaru
```
<br>
<br>
**Menentukan Cluster**

```{r}
# menentukan data baru di cluster mana
which.min(sapply(1:5, 
                 function(x) 
                   sum((databaru[Identitas.Cluster$field_yang_digunakan] - 
                          Identitas.Cluster$Segmentasi$centers[x,])^2)))
				 
Identitas.Cluster$Segmen.Pelanggan[which.min(sapply(1:5,
                                                    function(x) 
                                                      sum((databaru[Identitas.Cluster$field_yang_digunakan] -
                                                             Identitas.Cluster$Segmentasi$centers[x,])^2))),]
```

**min:** merupakan function untuk mencari nilai minimum
<br>
**1:5 :** adalah range nomor cluster dari 1 sampai dengan 5 (atau lebih sesuai dengan ukuran cluster)
<br>
**sapply:** digunakan untuk melakukan iterasi berdasarkan range (dalam kasus ini 1 s/d 5)
<br>
**function(x):** digunakan untuk proses dengan x diisi 1 s/d 5 per proses
<br>
**(data[kolom] – objekkmeans$centers[x,]) ^2:** adalah jarak kuadrat data. Ingat centers adalah komponen dari objek kmeans.
<br>
**sum:** digunakan untuk menjumlahkan jarak kuadrat


<br>
<br>
**Praktek terakhir menunjukkan bagaimana data pelanggan baru dianalisa oleh model kita dan mengeluarkan nomor cluster atau segmen. Dari hasil diatas databaru di masukkan ke clusster  3 pada segment Gold Young Professional**
